# ðŸ§µ ParalelizaÃ§Ã£o com OpenMP no GEMM do PolyBench

Este documento mostra como paralelizar o cÃ³digo GEMM (`gemm.c`) do benchmark PolyBench usando OpenMP, alÃ©m de como medir o speedup e testar diferentes estratÃ©gias de agendamento.

---

## âœ… Inserindo OpenMP

### ðŸ”§ Adicione o cabeÃ§alho `omp.h`

Logo apÃ³s os `#includes` no topo do arquivo:

```c
#include <omp.h>
```

---

ðŸ”„ Atualize a funÃ§Ã£o `kernel_gemm` com OpenMP

```c static
static
void kernel_gemm(int ni, int nj, int nk,
		 DATA_TYPE alpha,
		 DATA_TYPE beta,
		 DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj),
		 DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),
		 DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj))
{
  int i, j, k;

#pragma scop
  /* C := alpha*A*B + beta*C */
  #pragma omp parallel for private(i,j,k) shared(C,A,B,alpha,beta)
  for (i = 0; i < _PB_NI; i++)
    for (j = 0; j < _PB_NJ; j++)
      {
        C[i][j] *= beta;
        for (k = 0; k < _PB_NK; ++k)
          C[i][j] += alpha * A[i][k] * B[k][j];
      }
#pragma endscop
}
```

### âœ… **Notas importantes:**

- A paralelizaÃ§Ã£o ocorre no nÃ­vel do loop externo `i` (que geralmente Ã© a melhor escolha em matrizes grandes).
- Como cada iteraÃ§Ã£o de `i` atualiza `C[i][j]`, e nÃ£o hÃ¡ sobreposiÃ§Ã£o entre diferentes valores de `i`, nÃ£o hÃ¡ *data races*.
- A clÃ¡usula `private(i,j,k)` garante que cada thread tenha suas prÃ³prias variÃ¡veis locais para os Ã­ndices.
- `shared(...)` Ã© tecnicamente opcional se vocÃª jÃ¡ sabe que `C`, `A`, `B`, etc., sÃ£o visÃ­veis para todas as threads, mas Ã© boa prÃ¡tica declarar explicitamente.

### ðŸ”„ Atualize a funÃ§Ã£o `kernel_gemm` com OpenMP

Vamos usar `collapse(2)` para paralelizar **dois nÃ­veis de loop** (`i` e `j`) de uma vez sÃ³. Isso permite ao OpenMP distribuir melhor o trabalho entre as threads, especialmente quando o loop interno (`j`) tem iteraÃ§Ãµes suficientes para justificar o paralelismo extra.

#### âœ… VersÃ£o com `collapse(2)`

```c
static
void kernel_gemm(int ni, int nj, int nk,
		 DATA_TYPE alpha,
		 DATA_TYPE beta,
		 DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj),
		 DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),
		 DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj))
{
  int i, j, k;

#pragma scop
  /* C := alpha*A*B + beta*C */
  #pragma omp parallel for collapse(2) private(i,j,k) shared(C,A,B,alpha,beta)
  for (i = 0; i < _PB_NI; i++)
    for (j = 0; j < _PB_NJ; j++)
      {
        C[i][j] *= beta;
        for (k = 0; k < _PB_NK; ++k)
          C[i][j] += alpha * A[i][k] * B[k][j];
      }
#pragma endscop
}
```

---

### ðŸ§  **Por que isso pode ser melhor:**

- Quando o nÃºmero de threads Ã© alto, `collapse(2)` permite mais granularidade e melhor balanceamento de carga.
- Ãštil especialmente quando `ni` ou `nj` sÃ£o pequenos demais isoladamente, mas seu produto (`ni * nj`) Ã© grande.

---

### ðŸ› ï¸ **CompilaÃ§Ã£o com suporte ao OpenMP**

Use a flag `-fopenmp` ao compilar com `gcc` ou `clang`:

```bash
gcc -O2 -fopenmp -I utilities gemm.c -o gemm -lm
```

-----

## ðŸš€ Medindo Speedup

### ðŸ§ª CompilaÃ§Ã£o

#### Serial:
```bash
gcc -O2 gemm.c -o gemm_serial -lm
```

#### Paralelo:
```bash
gcc -O2 -fopenmp gemm.c -o gemm_omp -lm
```

---

### ðŸ§® ExecuÃ§Ã£o e comparaÃ§Ã£o

Execute ambos e compare o tempo usando os timers do PolyBench.

```bash
./gemm_serial
./gemm_omp
```

---

## âš™ï¸ Testando diferentes estratÃ©gias de `schedule`

VocÃª pode alterar a diretiva para explorar diferentes agendamentos:

```c
#pragma omp parallel for collapse(2) schedule(dynamic,16) private(i,j,k) shared(C,A,B,alpha,beta)
```

### Exemplos:

- `schedule(static)`
- `schedule(dynamic,32)`
- `schedule(guided)`

---

## ðŸ“Š Medir nÃºmero de threads

Adicione no `main()`:

```c
printf("Rodando com %d threads.\n", omp_get_max_threads());
```

E execute com diferentes valores de `OMP_NUM_THREADS`:

```bash
OMP_NUM_THREADS=2 ./gemm_omp
OMP_NUM_THREADS=4 ./gemm_omp
OMP_NUM_THREADS=8 ./gemm_omp
```

---

## ðŸ’¡ Automatizar os testes

Podemos usar um script para automatizar os testes de desempenho com diferentes estratÃ©gias de `schedule` e nÃºmeros de threads, o script `run_gemm_openmp.sh`:

```shell
#!/bin/bash

# Script: run_gemm_openmp.sh
# Objetivo: Rodar a versÃ£o paralela do GEMM com diferentes nÃºmeros de threads e agendamentos OpenMP

EXEC=./gemm_omp
SCHEDULES=("static" "dynamic,32" "guided")
THREADS=(1 2 4 8)

echo "Iniciando testes de performance com OpenMP"
echo "=========================================="

for sched in "${SCHEDULES[@]}"; do
  echo -e "\nSchedule: $sched"
  for t in "${THREADS[@]}"; do
    export OMP_NUM_THREADS=$t
    echo -e "\n[Threads: $t]"
    OMP_SCHEDULE=$sched $EXEC
  done
done
```



ðŸ“¥ Baixar script `run_gemm_openmp.sh`

### ðŸ§ª Como usar

1. Coloque o executÃ¡vel `gemm_omp` no mesmo diretÃ³rio do script.
2. Torne o script executÃ¡vel (se ainda nÃ£o estiver):

```bash
chmod +x run_gemm_openmp.sh
```

1. Execute:

```bash
./run_gemm_openmp.sh
```

Ele vai testar as combinaÃ§Ãµes de:

- `schedule(static)`
- `schedule(dynamic,32)`
- `schedule(guided)`

Com os seguintes valores de `OMP_NUM_THREADS`: **1, 2, 4, 8**.

Se quiser incluir mais estratÃ©gias ou threads, posso ajustar rapidinho! 
